{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKnuDy2att7Y",
        "outputId": "cac276a1-366d-4339-d7bb-d299bb70fa30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "(372451, 785)\n",
            "(201019, 785)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Load the dataset\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "file_path = \"/content/drive/My Drive/Problem_Statements/datasets/alphabets_28x28.csv\"\n",
        "# Function to convert label column\n",
        "def convert_label(x):\n",
        "    if isinstance(x, str) and len(x) == 1 and x.isalpha():\n",
        "        return ord(x) - ord('A')\n",
        "    else:\n",
        "        return np.nan\n",
        "# Function to convert other columns\n",
        "def convert_other_columns(x):\n",
        "    try:\n",
        "        return int(x)\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(file_path, converters={\n",
        "    'label': convert_label,\n",
        "    **{col: convert_other_columns for col in pd.read_csv(file_path, nrows=1).columns if col != 'label'}\n",
        "})\n",
        "#print(df.head())\n",
        "print(df.shape)\n",
        "# Remove unwanted rows\n",
        "df = df.dropna()\n",
        "# Remove duplicate rows based on all columns\n",
        "df = df.drop_duplicates()\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spilting of data into training, testing and validation dataset (equally distributed)\n",
        "num_labels = 26\n",
        "# Splitting ratios (adjust as needed)\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1  # Remaining 0.1 goes to test set automatically\n",
        "# Initialize empty lists for train, test, and val sets\n",
        "train_indices = []\n",
        "val_indices = []\n",
        "# Split data by label and then split each label's data\n",
        "for label in range(num_labels):\n",
        "    label_df = df[df['label'] == label]\n",
        "    # Randomly select indices for training\n",
        "    train_idx = np.random.choice(label_df.index, size=int(0.8*len(label_df)), replace=False)\n",
        "    train_indices.extend(train_idx)\n",
        "    # Remove selected indices from label_df\n",
        "    label_df = label_df.drop(train_idx)\n",
        "    # Randomly select indices for validation\n",
        "    val_idx = np.random.choice(label_df.index, size=int(0.5*len(label_df)), replace=False)\n",
        "    val_indices.extend(val_idx)\n",
        "    # Remaining indices go to test automatically\n",
        "# Create train, test, val DataFrames\n",
        "train_df = df.loc[train_indices]\n",
        "val_df = df.loc[val_indices]\n",
        "test_df = df.drop(train_indices).drop(val_indices)\n",
        "print(train_df.shape,test_df.shape,val_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmyhzfDX15rR",
        "outputId": "3b915fed-6558-4778-88a8-50a6f049d9d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(160807, 785) (20112, 785) (20100, 785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spilting the dataset into input and output labels\n",
        "X_train = train_df.drop('label',axis=1)\n",
        "y_train = train_df['label']\n",
        "X_test = test_df.drop('label',axis=1)\n",
        "y_test = test_df['label']\n",
        "X_val = val_df.drop('label',axis=1)\n",
        "y_val = val_df['label']\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape,X_val.shape,y_val.shape)"
      ],
      "metadata": {
        "id": "BRjL2HaR3DTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bff9e16-e17b-41c9-92e0-3b42c86d7fcf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(160807, 784) (160807,) (20112, 784) (20112,) (20100, 784) (20100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "X_train = tf.keras.utils.normalize(X_train,axis=1)\n",
        "X_test = tf.keras.utils.normalize(X_test,axis=1)\n",
        "X_val = tf.keras.utils.normalize(X_val,axis=1)\n",
        "print(set(y_train),len(set(y_train)))\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape,X_val.shape,y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnGQdHhCz6y0",
        "outputId": "de3e0a6d-6258-4332-d036-f7f087bd0c95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0} 26\n",
            "(160807, 784) (160807,) (20112, 784) (20112,) (20100, 784) (20100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "# no need for flattening as it is already flattened\n",
        "model.add(tf.keras.layers.Dense(512,activation='relu',input_shape = (784,)))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(512,activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(26,activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# Adding early stopping with patience\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',  # Monitors the validation loss\n",
        "    patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
        ")\n",
        "# Training the model with early stopping\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "tAjz_4oJ2M0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815fba25-498a-4560-db7b-a64909f38212"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5026/5026 [==============================] - 91s 18ms/step - loss: 0.4759 - accuracy: 0.8628 - val_loss: 0.1786 - val_accuracy: 0.9497\n",
            "Epoch 2/10\n",
            "5026/5026 [==============================] - 96s 19ms/step - loss: 0.2427 - accuracy: 0.9301 - val_loss: 0.1291 - val_accuracy: 0.9610\n",
            "Epoch 3/10\n",
            "5026/5026 [==============================] - 88s 17ms/step - loss: 0.2048 - accuracy: 0.9402 - val_loss: 0.1133 - val_accuracy: 0.9661\n",
            "Epoch 4/10\n",
            "5026/5026 [==============================] - 87s 17ms/step - loss: 0.1873 - accuracy: 0.9455 - val_loss: 0.1036 - val_accuracy: 0.9699\n",
            "Epoch 5/10\n",
            "5026/5026 [==============================] - 87s 17ms/step - loss: 0.1745 - accuracy: 0.9490 - val_loss: 0.1012 - val_accuracy: 0.9712\n",
            "Epoch 6/10\n",
            "5026/5026 [==============================] - 84s 17ms/step - loss: 0.1664 - accuracy: 0.9507 - val_loss: 0.0999 - val_accuracy: 0.9724\n",
            "Epoch 7/10\n",
            "5026/5026 [==============================] - 87s 17ms/step - loss: 0.1607 - accuracy: 0.9526 - val_loss: 0.0939 - val_accuracy: 0.9735\n",
            "Epoch 8/10\n",
            "5026/5026 [==============================] - 84s 17ms/step - loss: 0.1559 - accuracy: 0.9549 - val_loss: 0.0905 - val_accuracy: 0.9747\n",
            "Epoch 9/10\n",
            "5026/5026 [==============================] - 83s 17ms/step - loss: 0.1509 - accuracy: 0.9559 - val_loss: 0.0868 - val_accuracy: 0.9761\n",
            "Epoch 10/10\n",
            "5026/5026 [==============================] - 86s 17ms/step - loss: 0.1490 - accuracy: 0.9568 - val_loss: 0.0914 - val_accuracy: 0.9746\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c915447ab60>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJG7ghds8x1m",
        "outputId": "8dae02cf-dbc9-49da-8aaa-f761d04b0253"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0912 - accuracy: 0.9736\n",
            "Test Loss: 0.09116826206445694\n",
            "Test Accuracy: 0.9736475944519043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Functions to display image if required\n",
        "def display(im_data):\n",
        "  dpi = 80\n",
        "  height, width = im_data.shape\n",
        "  figsize = width / float(dpi), height / float(dpi)\n",
        "  fig = plt.figure(figsize=figsize)\n",
        "  ax = fig.add_axes([0, 0, 1, 1])\n",
        "  ax.axis('off')\n",
        "  ax.imshow(im_data, cmap='gray')\n",
        "  plt.show()\n",
        "def display2(im_data):\n",
        "  dpi = 80\n",
        "  height, width, depth = im_data.shape\n",
        "  figsize = width / float(dpi), height / float(dpi)\n",
        "  fig = plt.figure(figsize=figsize)\n",
        "  ax = fig.add_axes([0, 0, 1, 1])\n",
        "  ax.axis('off')\n",
        "  ax.imshow(im_data, cmap='gray')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "gcuzF0RV-m6v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "# Pre-processing the image as required by the dataset\n",
        "def preprocess_image(image_path):\n",
        "    img = cv.imread(image_path)\n",
        "    #print(image_path)\n",
        "    #display2(img)\n",
        "    #print(img.shape)\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "    #print(img.shape)\n",
        "    #display(img)\n",
        "    thresh, im_bw = cv.threshold(img, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
        "    #print(im_bw.shape)\n",
        "    #display(im_bw)\n",
        "    return im_bw"
      ],
      "metadata": {
        "id": "ezCroemhO4Dh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to define if the contour is valid or not\n",
        "def is_valid_contour(contour):\n",
        "    x, y, w, h = cv.boundingRect(contour)\n",
        "    aspect_ratio = w / float(h)\n",
        "    if w < 7 or h < 7:  # Minimum size\n",
        "        return False\n",
        "    if w > 100 or h > 100:  # Maximum size\n",
        "        return False\n",
        "    return True\n",
        "# Function which find valid contours in processed image and sorts it line wise\n",
        "def get_contours_line_wise(im_bw):\n",
        "  contours, _ = cv.findContours(im_bw, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "  # Filter out useless contours\n",
        "  contours = [c for c in contours if is_valid_contour(c)]\n",
        "  # Sort contours by their bounding rectangle's top-left corner coordinates (x, y)\n",
        "  contours = sorted(contours, key=lambda c: (cv.boundingRect(c)[1], cv.boundingRect(c)[0]))\n",
        "  # Group contours into lines based on y-coordinate with a threshold\n",
        "  threshold = 10  # Set your threshold value\n",
        "  lines = []\n",
        "  current_line = []\n",
        "  previous_y = -1\n",
        "  for contour in contours:\n",
        "      x, y, w, h = cv.boundingRect(contour)\n",
        "      if previous_y == -1:\n",
        "          previous_y = y\n",
        "      # If the current contour is not on the same line as the previous one\n",
        "      if abs(y - previous_y) > threshold:\n",
        "          lines.append(current_line)\n",
        "          current_line = []\n",
        "      current_line.append(contour)\n",
        "      previous_y = y\n",
        "      previous_x = x\n",
        "  # Don't forget to add the last line\n",
        "  if current_line:\n",
        "      lines.append(current_line)\n",
        "  #print(len(lines))\n",
        "  #img = cv.imread(image_path)\n",
        "  #contour_img = cv.drawContours(img.copy(), contours, -1, (0, 255, 0), 2)\n",
        "  #display2(contour_img)\n",
        "  return lines"
      ],
      "metadata": {
        "id": "puoNVfaeBNfp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get letter-wise images from line-wise contours\n",
        "def get_letters(lines):\n",
        "  letters = []\n",
        "  th_x = 25;\n",
        "  max_y = 0;\n",
        "  space_marker = np.zeros((28, 28))  # Placeholder for space\n",
        "  for line in lines:\n",
        "      previous_x = 0\n",
        "      sorted_line = sorted(line, key=lambda c: cv.boundingRect(c)[0])\n",
        "      for contour in sorted_line:\n",
        "          x, y, w, h = cv.boundingRect(contour)\n",
        "          if (x - previous_x) > th_x:\n",
        "              letters.append(space_marker)\n",
        "          # Get the bounding rectangle of the contour.\n",
        "          previous_x = x + w  # Update previous_x to the end of the current bounding box\n",
        "          letter = im_bw[y:y + h, x:x + w]\n",
        "          letter = cv.copyMakeBorder(letter, 5, 5, 5, 5, cv.BORDER_CONSTANT, value=0)\n",
        "          # Resize the letter to a standard size.\n",
        "          letter = cv.resize(letter, (28, 28))\n",
        "          # Add the letter to the list of identified letters.\n",
        "          letters.append(letter)\n",
        "      if (max_y - previous_x) > th_x:\n",
        "          letters.append(space_marker)\n",
        "      max_y = max(max_y, previous_x)\n",
        "  #fig = plt.figure(figsize=(120, 1))\n",
        "  #for i, letter in enumerate(letters):\n",
        "    #plt.subplot(1, len(letters), i + 1)\n",
        "    #plt.imshow(letter, cmap='gray')\n",
        "    #plt.axis('off')\n",
        "  #plt.show()\n",
        "  #print(len(letters))\n",
        "  return letters"
      ],
      "metadata": {
        "id": "izD0BNjvYWUL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict the sentence letter by letter using list of letter images\n",
        "def create_sentence(letters):\n",
        "  sentence = \"\"\n",
        "  # Process each letter and predict using the model\n",
        "  for letter in letters:\n",
        "      if np.all(letter == 0):  # Check if it's a space marker\n",
        "          sentence += \" \"\n",
        "          continue\n",
        "      # Normalize the letter\n",
        "      letter = tf.keras.utils.normalize(letter, axis=1)\n",
        "      # Reshape the letter for the model prediction\n",
        "      ch = model.predict(letter.reshape(1, 784))  # Ensure the shape is correct for the model\n",
        "      # Get the predicted character\n",
        "      c = np.argmax(ch)\n",
        "      sentence += chr(c + ord('A'))\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "DVmAJu5SaB4Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the lines images\n",
        "dir_path = \"/content/drive/My Drive/Problem_Statements/datasets/target_images\"\n",
        "lines = os.listdir(dir_path)\n",
        "sentences = {}\n",
        "for line in lines:\n",
        "    image_path = dir_path + \"/\" + line\n",
        "    im_bw = preprocess_image(image_path)\n",
        "    lines = get_contours_line_wise(im_bw)\n",
        "    letters = get_letters(lines)\n",
        "    sentence = create_sentence(letters)\n",
        "    #print(sentence)\n",
        "    sentences[line] = sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjik2RBD_fS_",
        "outputId": "18eaf905-e5f9-41ec-81d9-8bd28da3da1f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 192ms/step\n",
            "1/1 [==============================] - 0s 163ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 159ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 201ms/step\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicted Sentences from the model\n",
        "for line in sentences.keys():\n",
        "  print(line,sentences[line])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDdefEJGu86g",
        "outputId": "631f75a2-b0e7-4cdc-d332-93b5af6c9e15"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line_5.png YOUR ANALYSIS OF THE DDTA WRS ACCURATE AND UELL PRESENTED PROVIOING A CCEAR UNOERSTANDING OF TNE TRENDS ANO PATTERNS \n",
            "line_3.png E AM DELIGNTEO BY YOUR FRIENDLINESS ANO YOU ALWAYS MAKE EVERYONE FEEL WELCONE WHICH FOSTECS O SENSE OF COAQUNITY \n",
            "line_6.png TNE MEETING MINUTES YOU PREPARED UORE DETAILED AND WELL ORGANIZED ACCURATELY REFLEC ING THE DISCUSSZONS AND DECISIONS MADE \n",
            "line_1.png I AM REALLY ANNOYED BY YOUP CONSTANT COMPLAINING AAD YOU NEVER OFEER AN SOCUTIONS WHICH IS VERY UNHECPFUL AND NEGATSVS \n",
            "line_2.png IT IS ERUSTRATEOS TNAT YOU NEVER PAY ATTENTION DURING JISCUSSIONS ANO YOUR LACK OF FOCUS IS RLOLLY AFFECTING OUR PROGRESS \n",
            "line_4.png IT SS UONDERFUL TNAT YOU ALWEYS SHOW KZNDNESS ANO YOUR EMPATHY TOWARDS OTHECS IS TRULY HEARTWARMINS AND APPRECIATED \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the lines of Naive-Bayes Method\n",
        "dir_path = \"/content/drive/My Drive/Problem_Statements/datasets/sentiment_analysis_dataset.csv\"\n",
        "df_lines = pd.read_csv(dir_path)\n",
        "print(len(df_lines))"
      ],
      "metadata": {
        "id": "e_O1DCkgbLbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43e9d53-66e5-4b27-af13-b94975bb9198"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_lines = len(df_lines)\n",
        "C = list(set(df_lines['sentiment'].tolist()))\n",
        "prior = {}\n",
        "print(C)\n",
        "for c in C:\n",
        "  df_sent = df_lines[df_lines['sentiment'] == c]\n",
        "  prior[c] = len(df_sent)/N_lines\n",
        "print(prior)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_cL5SKhF_Nn",
        "outputId": "79297570-d754-4219-9930-63797018d27f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Neutral', 'Angry', 'Happy']\n",
            "{'Neutral': 0.3333333333333333, 'Angry': 0.3333333333333333, 'Happy': 0.3333333333333333}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = df_lines['line'].tolist()\n",
        "sentiments = df_lines['sentiment'].tolist()\n",
        "l = set()\n",
        "d = {}\n",
        "neg = ['NO','NEVER','NOT'] #negative words\n",
        "for (line,sentiment) in zip(lines,sentiments):\n",
        "  n = False # is negative word occured till now\n",
        "  words = line.split()\n",
        "  for word in words:\n",
        "    if n:\n",
        "      word = \"NOT_\" + word\n",
        "    if word in neg:\n",
        "      n = not n\n",
        "    l.add(word)\n",
        "    if word in d:\n",
        "      d[word][sentiment] += 1\n",
        "    else:\n",
        "      d[word] = {'Angry':0,'Neutral':0,'Happy':0}\n",
        "      d[word][sentiment] += 1\n",
        "print(len(l))\n",
        "print(l)\n",
        "token = pd.DataFrame.from_dict(d, orient='index')\n",
        "# Display the DataFrame\n",
        "print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "276uWKWz3_76",
        "outputId": "3bc5b28b-f5f5-49a7-a188-121ddda23da7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "308\n",
            "{'COMMUNICATION', 'PRESSURE', 'ADMIRABLE', 'FRESH', 'HURTFUL', 'KEY', 'USEFUL', 'WHICH', 'UNNECESSARY', 'HARD', 'NOT_YOUR', 'THROUGH', 'NOT_OF', 'COMMITMENTS', 'STAY', 'PEOPLE', 'LOT', 'EVERYONE', 'ARRIVE', 'NOT_INVOLVED', 'EVENT', 'WORKING', 'NOT_IT', 'PRESENTATION', 'NOT_EFFORT', 'PREPARED', 'NOT_ON', 'WELLWRITTEN', 'ACCORDING', 'UNDER', 'NOT_CONVERSATION', 'CANNOT', 'NOT_THROUGH', 'NOT_THE', 'TRULY', 'MESSAGES', 'ANGRY', 'THOROUGHNESS', 'YOU', 'DIFFERENCE', 'WITH', 'LISTEN', 'APPRECIATION', 'CLEAR', 'BELIEVE', 'ABILITY', 'INFURIATES', 'UPLIFTING', 'NOT_AND', 'FRUSTRATED', 'ATTENTION', 'NOT_RESPOND', 'FOLLOWED', 'THE', 'OTHERS', 'MAKE', 'NOT_LACK', 'FOCUSED', 'WHILE', 'NOT_WHOLE', 'CAUSING', 'NOT_YOU', 'TABLE', 'ATTITUDE', 'NOT_RESPECT', 'EMAIL', 'EASIER', 'MAJOR', 'ATTENDED', 'NOT_OTHERS', 'SUCCESS', 'YESTERDAY', 'NOT_LOT', 'VALUABLE', 'COVERING', 'WORK', 'NOT_VERY', 'NOT_PREPARE', 'WHEN', 'NOT_MISTAKES', 'THOROUGH', 'EVERYTHING', 'EXCUSES', 'MAKES', 'PRESENTING', 'TO', 'GREAT', 'APPRECIATE', 'CONCISE', 'DEADLINE', 'POINTS', 'NOT_A', 'DOWN', 'AM', 'DETAIL', 'INSPIRING', 'BENEFICIAL', 'NOT_TAKE', 'OUR', 'NOT_THEIR', 'NOT_DELAYS', 'RELIABILITY', 'EASY', 'PRACTICAL', 'YOUR', 'FEEL', 'BIG', 'ANOTHER', 'WORKPLACE', 'SUBJECT', 'POSITIVE', 'RECOMMENDED', 'NOT_THINGS', 'WILLINGNESS', 'EFFECTIVELY', 'TRAINING', 'NOT_DONE', 'INTERESTING', 'NOT_GET', 'BY', 'AGENDA', 'ENTHUSIASM', 'INSIGHTS', 'FEEDBACK', 'ASSIST', 'UPDATES', 'IMPROVE', 'INCLUDING', 'WILL', 'TRACK', 'KNOWLEDGE', 'EVERY', 'OPEN', 'MOTIVATES', 'SESSION', 'VALUED', 'AND', 'FORWARD', 'PROVIDED', 'PROJECTS', 'NOT_WRONG', 'NOT_BEHAVIOR', 'BEST', 'TIME', 'NOT_RESPONSIBILITY', 'NOT_APPRECIATE', 'MISSED', 'BEING', 'COMPREHENSIVELY', 'NOT_ACTIONS', 'MEETINGS', 'NOT_ANYONE', 'FOLLOW', 'NOT_TIME', 'NOT_CREDIT', 'IN', 'DO', 'AMAZING', 'RECOGNIZE', 'PRODUCTIVITY', 'INSIGHTFUL', 'IMPRESSED', 'NOT_GO', 'NOT_LET', 'NOT_LEARN', 'UPSETS', 'NOT_TO', 'NOT_NOT', 'MANNER', 'FOR', 'TASKS', 'CREATIVITY', 'A', 'NOT_DISRUPTING', 'NOT_IS', 'NOT_FOLLOW', 'THANKFUL', 'ME', 'NOT_ANYTHING', 'NOT_FROM', 'COME', 'PRODUCTIVE', 'THEIR', 'WAS', 'ADDRESSING', 'IT', 'IDEAS', 'BE', 'I', 'NOT_FOR', 'NECESSARY', 'NOT_BLAME', 'NOT_SITUATION', 'GOES', 'COVERED', 'CONDESCENDING', 'THAT', 'NOT_DO', 'PROVIDING', 'CONSTRUCTIVE', 'NOT_THOUGHTS', 'COMMUNICATE', 'UNDERSTAND', 'TODAY', 'HELP', 'NOT_UNRELIABLE', 'ON', 'TEAM', 'ANNOYS', 'PROBLEMS', 'NOT_DID', 'TOPIC', 'NOT_UNFAIR', 'NOT_EVERYONE', 'WRONG', 'ALLOWING', 'CLEARLY', 'IGNORE', 'HELPS', 'NOT_WHEN', 'REPORT', 'MEETING', 'MAKING', 'INTERRUPT', 'BECAUSE', 'NOT_WORK', 'DURING', 'NOT_UNPROFESSIONAL', 'WELLSTRUCTURED', 'QUALITY', 'MY', 'ENCOURAGE', 'NOT_MAKES', 'CONTAGIOUS', 'ALWAYS', 'MATTER', 'BRING', 'NOT_PEOPLES', 'SUPPORT', 'FANTASTIC', 'OFFER', 'NOT_WHICH', 'WELLORGANIZED', 'NOT_MEETINGS', 'HAVE', 'ARTICLE', 'GRATEFUL', 'COMPOSURE', 'UNACCEPTABLE', 'NOT_HARD', 'NOT_PROMISES', 'CONVEY', 'DISAPPOINTING', 'GOOD', 'NOT_EVIDENT', 'LACK', 'REASSURING', 'ENTIRE', 'NOT_FRUSTRATION', 'KEEP', 'WORKSHOP', 'NOT_WORSENING', 'SMOOTHLY', 'NOT_OTHER', 'NOT_DISAPPOINTING', 'TIRED', 'INFORMATIVE', 'UPSET', 'VERY', 'EFFORTS', 'DISCUSSION', 'PLAN', 'SOMETHING', 'WONDERFUL', 'IS', 'MOVING', 'CAREFULLY', 'DAILY', 'NOT_SEEM', 'LATE', 'INFORMATION', 'NOT_CAUSING', 'NOT_ALWAYS', 'ALL', 'NOT_PROBLEMS', 'HOW', 'OVERVIEW', 'FOUND', 'EXCHANGE', 'REALLY', 'NEVER', 'HELPFUL', 'NOT_FINISH', 'ENJOYABLE', 'OF', 'ENSURING', 'STAND', 'CALM', 'CREATES', 'ENVIRONMENT', 'WENT', 'SKILLS', 'HAPPY', 'IMPORTANT', 'DETAILED', 'TALK', 'CONSTANTLY', 'NOT_WITH'}\n",
            "               Angry  Neutral  Happy\n",
            "I                  5        3      5\n",
            "AM                 3        0      4\n",
            "REALLY             3        0      1\n",
            "FRUSTRATED         1        0      0\n",
            "BECAUSE            2        0      1\n",
            "...              ...      ...    ...\n",
            "PRODUCTIVE         0        1      0\n",
            "ALLOWING           0        1      0\n",
            "OPEN               0        1      0\n",
            "COMMUNICATION      0        1      0\n",
            "EXCHANGE           0        1      0\n",
            "\n",
            "[308 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "den_likelihood = {'Angry':0,'Neutral':0,'Happy':0}\n",
        "for word in l:\n",
        "  for c in C:\n",
        "    den_likelihood[c] += d[word][c]+1\n",
        "print(den_likelihood)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bQFv7jjQdy8",
        "outputId": "af0b32a9-fa3e-46a5-ce4e-0eda95e137da"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Angry': 538, 'Neutral': 490, 'Happy': 509}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(line_name):\n",
        "  pred_line = sentences[line_name]\n",
        "  #print(pred_line)\n",
        "  pred_words = pred_line.split()\n",
        "  n = False\n",
        "  words_used = set()\n",
        "  for word in pred_words:\n",
        "    if n:\n",
        "      word = \"NOT_\" + word\n",
        "    if word in neg:\n",
        "      n = not n\n",
        "    if word in d:\n",
        "      words_used.add(word)\n",
        "  #print(words_used)\n",
        "  ans = []\n",
        "  for c in C:\n",
        "    sum = prior[c]\n",
        "    for word in words_used:\n",
        "      if word in l:\n",
        "        sum *= (d[word][c]+1)/den_likelihood[c]\n",
        "    ans.append(sum)\n",
        "  ans = np.array(ans)\n",
        "  #print(line_name, ans)\n",
        "  #print(C[ans.argmax()])\n",
        "  return C[ans.argmax()]"
      ],
      "metadata": {
        "id": "w2KSnEfJ7Qtw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the actual sentiment of the lines\n",
        "dir_path = \"/content/drive/My Drive/Problem_Statements/datasets/target_labels.csv\"\n",
        "df_sent = pd.read_csv(dir_path)\n",
        "print(df_sent)\n",
        "df_sent.insert(2,\"predicted_sentiment\",[predict(line_name) for line_name in df_sent['file']])\n",
        "print(df_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEJqqQF172Fi",
        "outputId": "56d66e34-7a9d-4bb1-bf12-f00f7ba4f10c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         file sentiment\n",
            "0  line_1.png     Angry\n",
            "1  line_2.png     Angry\n",
            "2  line_3.png     Happy\n",
            "3  line_4.png     Happy\n",
            "4  line_5.png   Neutral\n",
            "5  line_6.png   Neutral\n",
            "         file sentiment predicted_sentiment\n",
            "0  line_1.png     Angry               Angry\n",
            "1  line_2.png     Angry               Angry\n",
            "2  line_3.png     Happy               Happy\n",
            "3  line_4.png     Happy               Happy\n",
            "4  line_5.png   Neutral             Neutral\n",
            "5  line_6.png   Neutral             Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (df_sent['sentiment'] == df_sent['predicted_sentiment']).sum()/len(df_sent)\n",
        "print(accuracy*100,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfouainYC13x",
        "outputId": "f8228ec5-e917-49be-eb76-82e76711a14f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though the predicted lines are not that accurate, Naive Bayes Method is able to predict the sentiment of the line correctly.\n",
        "\n",
        "* Tried adding a token of NOT_ at the beginning of the word after an occurrence of negative word in the sentence.\n",
        "* We should stop adding NOT_ if we encounter any punctuation or another negative word.\n",
        "* Since it is a single line, we stop adding only when another negative word encountered.\n",
        "\n",
        "Adding this token didn't affect the final results in this case but this will be a good practice. I believe if any other dataset was given, the result may vary according to addition of token. Since, it will separate the negative meaning positive words and it will totally deny the existence of that positive word in the sentence.\n"
      ],
      "metadata": {
        "id": "exVlmJeCdvX0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Jb9RgEua0Tv"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}